{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3952901,"sourceType":"datasetVersion","datasetId":2346045}],"dockerImageVersionId":30177,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install opencv-python==4.5.5.62\n!pip install opencv-contrib-python==4.5.5.62\n!pip install tf-explain\n!pip install keras_applications\n!pip install git+https://github.com/dineshssdn-867/keras-squeezenet","metadata":{"execution":{"iopub.status.busy":"2025-12-08T14:27:31.289658Z","iopub.execute_input":"2025-12-08T14:27:31.289926Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python==4.5.5.62 in /opt/conda/lib/python3.7/site-packages (4.5.5.62)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python==4.5.5.62) (1.19.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: opencv-contrib-python==4.5.5.62 in /opt/conda/lib/python3.7/site-packages (4.5.5.62)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-contrib-python==4.5.5.62) (1.19.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: tf-explain in /opt/conda/lib/python3.7/site-packages (0.3.1)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport sys\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport skimage\nfrom skimage.feature import hog, canny\nfrom skimage.filters import sobel\nfrom skimage import color\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom keras import layers\nimport keras.backend as K\nfrom keras.models import Sequential, Model\nfrom keras.preprocessing import image\nfrom keras.layers import Input, Dense, Activation, Dropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D \nfrom keras.applications.imagenet_utils import preprocess_input\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tf_explain.core.grad_cam import GradCAM\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.data_utils import get_file\nfrom keras_squeezenet import SqueezeNet\n\nfrom PIL import Image\nfrom tqdm import tqdm\nimport random as rnd\nimport cv2\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom numpy import expand_dims\n\n!pip install livelossplot\nfrom livelossplot import PlotLossesKeras\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2025-12-08T14:27:05.776467Z","iopub.execute_input":"2025-12-08T14:27:05.777190Z","iopub.status.idle":"2025-12-08T14:27:13.729317Z","shell.execute_reply.started":"2025-12-08T14:27:05.777147Z","shell.execute_reply":"2025-12-08T14:27:13.726201Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: livelossplot in /opt/conda/lib/python3.7/site-packages (0.5.6)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from livelossplot) (3.5.1)\nRequirement already satisfied: numpy<1.22 in /opt/conda/lib/python3.7/site-packages (from livelossplot) (1.19.5)\nRequirement already satisfied: bokeh in /opt/conda/lib/python3.7/site-packages (from livelossplot) (2.4.2)\nRequirement already satisfied: ipython==7.* in /opt/conda/lib/python3.7/site-packages (from livelossplot) (7.30.1)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (0.2.0)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (59.5.0)\nRequirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (2.10.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (0.18.1)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (0.7.5)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (4.8.0)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (0.1.3)\nRequirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (5.1.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (5.1.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython==7.*->livelossplot) (3.0.24)\nRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh->livelossplot) (6.0)\nRequirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.7/site-packages (from bokeh->livelossplot) (3.0.3)\nCollecting typing-extensions>=3.10.0\n  Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nRequirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.7/site-packages (from bokeh->livelossplot) (8.2.0)\nRequirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh->livelossplot) (21.3)\nRequirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.7/site-packages (from bokeh->livelossplot) (6.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->livelossplot) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->livelossplot) (1.3.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->livelossplot) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->livelossplot) (4.28.4)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->livelossplot) (3.0.6)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython==7.*->livelossplot) (0.8.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.1)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython==7.*->livelossplot) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython==7.*->livelossplot) (0.2.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.15.0)\nInstalling collected packages: typing-extensions\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4.3\n    Uninstalling typing-extensions-3.7.4.3:\n      Successfully uninstalled typing-extensions-3.7.4.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nexplainable-ai-sdk 1.3.2 requires xai-image-widget, which is not installed.\nthinc 8.0.15 requires typing-extensions<4.0.0.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.7.1 which is incompatible.\ntensorflow 2.6.2 requires typing-extensions~=3.7.4, but you have typing-extensions 4.7.1 which is incompatible.\ntensorflow-transform 1.5.0 requires absl-py<0.13,>=0.9, but you have absl-py 0.15.0 which is incompatible.\ntensorflow-transform 1.5.0 requires pyarrow<6,>=1, but you have pyarrow 6.0.1 which is incompatible.\ntensorflow-transform 1.5.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,<2.8,>=1.15.2, but you have tensorflow 2.6.2 which is incompatible.\ntensorflow-serving-api 2.7.0 requires tensorflow<3,>=2.7.0, but you have tensorflow 2.6.2 which is incompatible.\nspacy 3.2.3 requires typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.7.1 which is incompatible.\nflake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.11.3 which is incompatible.\narviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.7.1 which is incompatible.\napache-beam 2.34.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\napache-beam 2.34.0 requires httplib2<0.20.0,>=0.8, but you have httplib2 0.20.2 which is incompatible.\napache-beam 2.34.0 requires pyarrow<6.0.0,>=0.15.1, but you have pyarrow 6.0.1 which is incompatible.\napache-beam 2.34.0 requires typing-extensions<4,>=3.7.0, but you have typing-extensions 4.7.1 which is incompatible.\naiobotocore 2.1.2 requires botocore<1.23.25,>=1.23.24, but you have botocore 1.24.20 which is incompatible.\u001b[0m\nSuccessfully installed typing-extensions-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_19/2732112853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install livelossplot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotLossesKeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/livelossplot/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmain_logger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMainLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mplot_losses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlotLosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/livelossplot/plot_losses.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlivelossplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlivelossplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_logger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMainLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Literal' from 'typing' (/opt/conda/lib/python3.7/typing.py)"],"ename":"ImportError","evalue":"cannot import name 'Literal' from 'typing' (/opt/conda/lib/python3.7/typing.py)","output_type":"error"}],"execution_count":4},{"cell_type":"markdown","source":"# Loading Dataset\nWe'll use here the Pandas to load the dataset into memory","metadata":{}},{"cell_type":"code","source":"train_main_path = '../input/cattle-disease/train/'\npath_train_FMD = train_main_path + 'FMD'\npath_train_IBK = train_main_path + 'IBK'\npath_train_LSD = train_main_path + 'LSD'","metadata":{"execution":{"iopub.status.busy":"2025-12-08T14:27:13.730195Z","iopub.status.idle":"2025-12-08T14:27:13.730466Z","shell.execute_reply.started":"2025-12-08T14:27:13.730321Z","shell.execute_reply":"2025-12-08T14:27:13.730343Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.DataFrame()","metadata":{"execution":{"iopub.status.busy":"2025-12-08T14:27:13.732104Z","iopub.status.idle":"2025-12-08T14:27:13.732363Z","shell.execute_reply.started":"2025-12-08T14:27:13.732224Z","shell.execute_reply":"2025-12-08T14:27:13.732239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = []\npaths = []\n\ndirs = [path_train_FMD, path_train_IBK, path_train_LSD]\nfor image_dir in dirs:\n    for image in os.listdir(image_dir):\n        class_ = image_dir.split('/')[4]\n        classes.append(class_)\n        paths.append(image_dir+'/'+image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.733416Z","iopub.status.idle":"2025-12-08T14:27:13.733690Z","shell.execute_reply.started":"2025-12-08T14:27:13.733548Z","shell.execute_reply":"2025-12-08T14:27:13.733564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['classname'] = classes\ntrain_df['path'] = paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.734394Z","iopub.status.idle":"2025-12-08T14:27:13.734654Z","shell.execute_reply.started":"2025-12-08T14:27:13.734522Z","shell.execute_reply":"2025-12-08T14:27:13.734536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.tail(100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.735867Z","iopub.status.idle":"2025-12-08T14:27:13.736134Z","shell.execute_reply.started":"2025-12-08T14:27:13.735979Z","shell.execute_reply":"2025-12-08T14:27:13.736000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" i=train_df.loc[train_df[\"path\"] == '../input/cattle-disease/train/FMD/desktop.ini'].index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.737305Z","iopub.status.idle":"2025-12-08T14:27:13.737739Z","shell.execute_reply.started":"2025-12-08T14:27:13.737495Z","shell.execute_reply":"2025-12-08T14:27:13.737533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = train_df.drop(train_df.index[i])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.739689Z","iopub.status.idle":"2025-12-08T14:27:13.740298Z","shell.execute_reply.started":"2025-12-08T14:27:13.740072Z","shell.execute_reply":"2025-12-08T14:27:13.740096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = {'FMD': 'Foot-and-mouth disease',\n'IBK': 'Infectious Bovine Keratoconjunctivitis',\n'LSD': ' lysergic acid diethylamide',}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.741402Z","iopub.status.idle":"2025-12-08T14:27:13.741895Z","shell.execute_reply.started":"2025-12-08T14:27:13.741680Z","shell.execute_reply":"2025-12-08T14:27:13.741702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.743127Z","iopub.status.idle":"2025-12-08T14:27:13.743507Z","shell.execute_reply.started":"2025-12-08T14:27:13.743291Z","shell.execute_reply":"2025-12-08T14:27:13.743312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Train samples count: ', len(train_df))\ntrain_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.744356Z","iopub.status.idle":"2025-12-08T14:27:13.744743Z","shell.execute_reply.started":"2025-12-08T14:27:13.744532Z","shell.execute_reply":"2025-12-08T14:27:13.744552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Class Count: ',len(train_df['classname'].value_counts()))\ntrain_df['classname'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.745765Z","iopub.status.idle":"2025-12-08T14:27:13.746126Z","shell.execute_reply.started":"2025-12-08T14:27:13.745925Z","shell.execute_reply":"2025-12-08T14:27:13.745944Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Checking missing data\nLets check if there is any missing values in our dataset","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.747535Z","iopub.status.idle":"2025-12-08T14:27:13.747913Z","shell.execute_reply.started":"2025-12-08T14:27:13.747712Z","shell.execute_reply":"2025-12-08T14:27:13.747732Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization\nLooking at some random beauties\nIt's a great deal of fun to explore the data and play around with matplotlib","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20,18))\nfor idx,i in enumerate(train_df.classname.unique()):\n    plt.subplot(4,7,idx+1)\n    df = train_df[train_df['classname'] ==i].reset_index(drop = True)\n    image_path = df.loc[rnd.randint(0, len(df))-1,'path']\n    img = Image.open(image_path)\n    img = img.resize((224,224))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(classes[i])\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.749256Z","iopub.status.idle":"2025-12-08T14:27:13.749543Z","shell.execute_reply.started":"2025-12-08T14:27:13.749376Z","shell.execute_reply":"2025-12-08T14:27:13.749399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_species(df,class_name):\n    plt.figure(figsize = (20,18))\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    plt.suptitle(classes[class_name])\n    for idx,i in enumerate(np.random.choice(classes_df['path'],32)):\n        plt.subplot(8,8,idx+1)\n        image_path = i\n        img = Image.open(image_path)\n        img = img.resize((224,224))\n        plt.imshow(img)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.750527Z","iopub.status.idle":"2025-12-08T14:27:13.750783Z","shell.execute_reply.started":"2025-12-08T14:27:13.750644Z","shell.execute_reply":"2025-12-08T14:27:13.750665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for class_ in train_df['classname'].unique():\n    #print('\\n\\n')\n    plot_species(train_df , class_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.751794Z","iopub.status.idle":"2025-12-08T14:27:13.752025Z","shell.execute_reply.started":"2025-12-08T14:27:13.751905Z","shell.execute_reply":"2025-12-08T14:27:13.751918Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Class Distribution AnalysisÂ¶\nIn this section we will be analyzing the number of training and test samples in each class. It will give us a better understanding of our dataset and provide us the necessary information to preprocess our dataset before the training phase.","metadata":{}},{"cell_type":"code","source":"plot = sns.countplot(x = train_df['classname'], color = '#2596be')\nsns.set(rc={'figure.figsize':(30,25)})\nsns.despine()\nplot.set_title('Class Distribution\\n', font = 'serif', x = 0.1, y=1, fontsize = 18);\nplot.set_ylabel(\"Count\", x = 0.02, font = 'serif', fontsize = 12)\nplot.set_xlabel(\"Disease classes\", fontsize = 15, font = 'serif')\n\nfor p in plot.patches:\n    plot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2, p.get_height()), \n       ha = 'center', va = 'center', xytext = (0, -20),font = 'serif', textcoords = 'offset points', size = 15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.752933Z","iopub.status.idle":"2025-12-08T14:27:13.753177Z","shell.execute_reply.started":"2025-12-08T14:27:13.753045Z","shell.execute_reply":"2025-12-08T14:27:13.753066Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nclass_cnt = train_df.groupby(['classname']).size().reset_index(name = 'counts')\ncolors = sns.color_palette('Paired')[0:9]\nplt.pie(class_cnt['counts'], labels=class_cnt['classname'], colors=colors, autopct='%1.1f%%')\nplt.legend(loc='upper right')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.753875Z","iopub.status.idle":"2025-12-08T14:27:13.754123Z","shell.execute_reply.started":"2025-12-08T14:27:13.753982Z","shell.execute_reply":"2025-12-08T14:27:13.754002Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Image Resolutions","metadata":{}},{"cell_type":"code","source":"widths, heights = [], []\n\nfor path in tqdm(train_df[\"path\"]):\n    width, height = Image.open(path).size\n    widths.append(width)\n    heights.append(height)\n    \ntrain_df[\"width\"] = widths\ntrain_df[\"height\"] = heights\ntrain_df[\"dimension\"] = train_df[\"width\"] * train_df[\"height\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.755227Z","iopub.status.idle":"2025-12-08T14:27:13.755622Z","shell.execute_reply.started":"2025-12-08T14:27:13.755391Z","shell.execute_reply":"2025-12-08T14:27:13.755411Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Lets see some small images**","metadata":{}},{"cell_type":"code","source":"train_df.sort_values('width').head(84)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.756973Z","iopub.status.idle":"2025-12-08T14:27:13.757336Z","shell.execute_reply.started":"2025-12-08T14:27:13.757137Z","shell.execute_reply":"2025-12-08T14:27:13.757157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Let us know the average input size**","metadata":{}},{"cell_type":"code","source":"train_df.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.759565Z","iopub.status.idle":"2025-12-08T14:27:13.759834Z","shell.execute_reply.started":"2025-12-08T14:27:13.759699Z","shell.execute_reply":"2025-12-08T14:27:13.759718Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Color Analysis\nWe need to do some color analysis to get an ida about the augmentation technique needed for this problem","metadata":{}},{"cell_type":"code","source":"def is_grey_scale(givenImage):\n    w,h = givenImage.size\n    for i in range(w):\n        for j in range(h):\n            r,g,b = givenImage.getpixel((i,j))\n            if r != g != b: return False\n    return True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.761048Z","iopub.status.idle":"2025-12-08T14:27:13.761314Z","shell.execute_reply.started":"2025-12-08T14:27:13.761165Z","shell.execute_reply":"2025-12-08T14:27:13.761188Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Check color scale of Train images**","metadata":{}},{"cell_type":"code","source":"sampleFrac = 0.5\n#get our sampled images\nisGreyList = []\nfor imageName in train_df['path'].sample(frac=sampleFrac):\n    val = Image.open(imageName).convert('RGB')\n    isGreyList.append(is_grey_scale(val))\nprint(np.sum(isGreyList) / len(isGreyList))\ndel isGreyList","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.762627Z","iopub.status.idle":"2025-12-08T14:27:13.762899Z","shell.execute_reply.started":"2025-12-08T14:27:13.762739Z","shell.execute_reply":"2025-12-08T14:27:13.762762Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Get mean intensity for each channel RGB**","metadata":{}},{"cell_type":"code","source":"def get_rgb_men(row):\n    img = cv2.imread(row['path'])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return np.sum(img[:,:,0]), np.sum(img[:,:,1]), np.sum(img[:,:,2])\n\ntqdm.pandas()\ntrain_df['R'], train_df['G'], train_df['B'] = zip(*train_df.progress_apply(lambda row: get_rgb_men(row), axis=1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.764252Z","iopub.status.idle":"2025-12-08T14:27:13.764549Z","shell.execute_reply.started":"2025-12-08T14:27:13.764370Z","shell.execute_reply":"2025-12-08T14:27:13.764392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_color_dist(df, count):\n    fig, axr = plt.subplots(count,2,figsize=(15,15))\n    if df.empty:\n        print(\"Image internsity of selected color is weak\")\n        return\n    for idx, i in enumerate(np.random.choice(df['path'], count)):\n        img = cv2.imread(i)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axr[idx,0].imshow(img)\n        axr[idx,0].axis('off')\n        axr[idx,1].set_title('R={:.0f}, G={:.0f}, B={:.0f} '.format(np.mean(img[:,:,0]), np.mean(img[:,:,1]), np.mean(img[:,:,2]))) \n        x, y = np.histogram(img[:,:,0], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='R', alpha=0.8, color='red')\n        x, y = np.histogram(img[:,:,1], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='G', alpha=0.8, color='green')\n        x, y = np.histogram(img[:,:,2], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='B', alpha=0.8, color='blue')\n        axr[idx,1].legend()\n        axr[idx,1].axis('off')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.765929Z","iopub.status.idle":"2025-12-08T14:27:13.766293Z","shell.execute_reply.started":"2025-12-08T14:27:13.766091Z","shell.execute_reply":"2025-12-08T14:27:13.766112Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Red images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[((train_df['B']) < train_df['R']) & ((train_df['G']) < train_df['R'])]\nif df.size != 0:\n    show_color_dist(df, 8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.767237Z","iopub.status.idle":"2025-12-08T14:27:13.767631Z","shell.execute_reply.started":"2025-12-08T14:27:13.767397Z","shell.execute_reply":"2025-12-08T14:27:13.767417Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Green images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[(train_df['G'] > train_df['R']) & (train_df['G'] > train_df['B'])]\nif df.size != 0:\n    show_color_dist(df, 8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.768653Z","iopub.status.idle":"2025-12-08T14:27:13.769013Z","shell.execute_reply.started":"2025-12-08T14:27:13.768815Z","shell.execute_reply":"2025-12-08T14:27:13.768834Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Blue images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[(train_df['B'] > train_df['R']) & (train_df['B'] > train_df['G'])]\nif df.size != 0:\n    show_color_dist(df, 8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.769934Z","iopub.status.idle":"2025-12-08T14:27:13.770183Z","shell.execute_reply.started":"2025-12-08T14:27:13.770045Z","shell.execute_reply":"2025-12-08T14:27:13.770066Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"markdown","source":"## Analyzing Edges\nA Sobel filter is one means of getting a basic edge magnitude/gradient image. Can be useful to threshold and find prominent linear features, etc. Several other similar filters in skimage.filters are also good edge detectors: roberts, scharr, etc. and you can control direction, i.e. use an anisotropic version.","metadata":{}},{"cell_type":"code","source":"def edges_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],2)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        edges = sobel(image)\n        gray_edges=sobel(gray)\n        dimension = edges.shape\n        fig = plt.figure(figsize=(8, 8))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(gray_edges)\n        plt.subplot(2,2,2)\n        plt.imshow(edges[:dimension[0],:dimension[1],0], cmap=\"gray\")\n        plt.subplot(2,2,3)\n        plt.imshow(edges[:dimension[0],:dimension[1],1], cmap='gray')\n        plt.subplot(2,2,4)\n        plt.imshow(edges[:dimension[0],:dimension[1],2], cmap='gray')\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.771738Z","iopub.status.idle":"2025-12-08T14:27:13.771970Z","shell.execute_reply.started":"2025-12-08T14:27:13.771851Z","shell.execute_reply":"2025-12-08T14:27:13.771864Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    edges_images_gray(class_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.773025Z","iopub.status.idle":"2025-12-08T14:27:13.773281Z","shell.execute_reply.started":"2025-12-08T14:27:13.773141Z","shell.execute_reply":"2025-12-08T14:27:13.773162Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# HSV Transform\nSince this contest is about time series ordering, I think it's possible there may be useful information in a transform to HSV color space. HSV is useful for identifying shadows and illumination, as well as giving us a means to identify similar objects that are distinct by color between scenes (hue), though there's no guarantee the hue will be stable.","metadata":{}},{"cell_type":"code","source":"def hsv_images(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(train_df['path'],2)):  \n        image = cv2.imread(i)\n        hsv = color.rgb2hsv(image)\n        dimension = hsv.shape\n        fig = plt.figure(figsize=(8, 8))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(image)\n        plt.subplot(2,2,2)\n        plt.imshow(hsv[:dimension[0],:dimension[1],0], cmap=\"PuBuGn\")\n        plt.subplot(2,2,3)\n        plt.imshow(hsv[:dimension[0],:dimension[1],1], cmap='PuBuGn')\n        plt.subplot(2,2,4)\n        plt.imshow(hsv[:dimension[0],:dimension[1],2], cmap='PuBuGn')\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.774747Z","iopub.status.idle":"2025-12-08T14:27:13.774983Z","shell.execute_reply.started":"2025-12-08T14:27:13.774864Z","shell.execute_reply":"2025-12-08T14:27:13.774876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    hsv_images(class_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.775581Z","iopub.status.idle":"2025-12-08T14:27:13.775824Z","shell.execute_reply.started":"2025-12-08T14:27:13.775701Z","shell.execute_reply":"2025-12-08T14:27:13.775713Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Corners","metadata":{}},{"cell_type":"code","source":"def corners_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        corners_gray = cv2.goodFeaturesToTrack(gray, maxCorners=50, qualityLevel=0.02, minDistance=20)\n        corners_gray = np.float32(corners_gray)\n        for item in corners_gray:\n            x, y = item[0]\n            cv2.circle(image, (int(x), int(y)), 6, (0, 255, 0), -1)\n        fig = plt.figure(figsize=(16, 16))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(image, cmap=\"BuGn\")\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.776945Z","iopub.status.idle":"2025-12-08T14:27:13.777199Z","shell.execute_reply.started":"2025-12-08T14:27:13.777062Z","shell.execute_reply":"2025-12-08T14:27:13.777084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    corners_images_gray(class_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.778279Z","iopub.status.idle":"2025-12-08T14:27:13.778572Z","shell.execute_reply.started":"2025-12-08T14:27:13.778393Z","shell.execute_reply":"2025-12-08T14:27:13.778414Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Sift Features","metadata":{}},{"cell_type":"code","source":"def sift_images_gray(class_name):\n    classes_df = train_df[train_df['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        sift = cv2.SIFT_create()\n        kp, des = sift.detectAndCompute(gray, None)\n        kp_img = cv2.drawKeypoints(image, kp, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n        fig = plt.figure(figsize=(16, 16))\n        plt.suptitle(classes[class_name])\n        plt.subplot(2,2,1)\n        plt.imshow(kp_img, cmap=\"viridis\")\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.779434Z","iopub.status.idle":"2025-12-08T14:27:13.779735Z","shell.execute_reply.started":"2025-12-08T14:27:13.779588Z","shell.execute_reply":"2025-12-08T14:27:13.779610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    sift_images_gray(class_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.780809Z","iopub.status.idle":"2025-12-08T14:27:13.781039Z","shell.execute_reply.started":"2025-12-08T14:27:13.780920Z","shell.execute_reply":"2025-12-08T14:27:13.780932Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot Augmentations","metadata":{}},{"cell_type":"code","source":"def plot_augimages(paths, datagen):\n    plt.figure(figsize = (14,28))\n    plt.suptitle('Augmented Images')\n    \n    midx = 0\n    for path in paths:\n        data = Image.open(path)\n        data = data.resize((224,224))\n        samples = expand_dims(data, 0)\n        it = datagen.flow(samples, batch_size=1)\n    \n        # Show Original Image\n        plt.subplot(10,5, midx+1)\n        plt.imshow(data)\n        plt.axis('off')\n    \n        # Show Augmented Images\n        for idx, i in enumerate(range(4)):\n            midx += 1\n            plt.subplot(10,5, midx+1)\n            \n            batch = it.next()\n            image = batch[0].astype('uint8')\n            plt.imshow(image)\n            plt.axis('off')\n        midx += 1\n    \n    plt.tight_layout()\n    plt.show()\n\n    \ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest'\n) \nplot_augimages(np.random.choice(train_df['path'],10), datagen)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.782210Z","iopub.status.idle":"2025-12-08T14:27:13.782597Z","shell.execute_reply.started":"2025-12-08T14:27:13.782371Z","shell.execute_reply":"2025-12-08T14:27:13.782393Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"code","source":"y_count=len(train_df['classname'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.783747Z","iopub.status.idle":"2025-12-08T14:27:13.784124Z","shell.execute_reply.started":"2025-12-08T14:27:13.783915Z","shell.execute_reply":"2025-12-08T14:27:13.783937Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Mobilenet","metadata":{}},{"cell_type":"code","source":"# include_top = False means that we doesnt include fully connected top layer we will add them accordingly\nmobilenetV2 = MobileNetV2(include_top = False, input_shape = (224,224,3), weights = 'imagenet')\n\n# training of all the convolution is set to false\nfor layer in mobilenetV2.layers:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(mobilenetV2.output)\npredictions = Dense(y_count, activation='softmax')(x)\n\nmodel_mobilenetV2 = Model(inputs = mobilenetV2.input, outputs = predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.785467Z","iopub.status.idle":"2025-12-08T14:27:13.785875Z","shell.execute_reply.started":"2025-12-08T14:27:13.785664Z","shell.execute_reply":"2025-12-08T14:27:13.785685Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## SqueezeNet","metadata":{}},{"cell_type":"code","source":"squeezeNet = SqueezeNet(input_shape = (224,224,3))\n\nfor layer in squeezeNet.layers:\n    layer.trainable = True\n\noutput = Dense(y_count,activation=\"softmax\")(squeezeNet.layers[-2].output)\nmodel_squeezeNet = Model(squeezeNet.input,output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.787113Z","iopub.status.idle":"2025-12-08T14:27:13.787493Z","shell.execute_reply.started":"2025-12-08T14:27:13.787274Z","shell.execute_reply":"2025-12-08T14:27:13.787294Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Own Proposed Model","metadata":{}},{"cell_type":"code","source":"def create_model():\n    model = Sequential()\n\n    ## CNN 1\n    model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64, 64, 3)))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(32,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 2\n    model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.3))\n\n    ## CNN 3\n    model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n    model.add(BatchNormalization(axis = 3))\n    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n    model.add(Dropout(0.5))\n\n    ## Output\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(3,activation='softmax'))\n\n    return model\n\n\ncustom_model = create_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.790652Z","iopub.status.idle":"2025-12-08T14:27:13.790939Z","shell.execute_reply.started":"2025-12-08T14:27:13.790792Z","shell.execute_reply":"2025-12-08T14:27:13.790817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Compile Model","metadata":{}},{"cell_type":"markdown","source":"### Mobilenet","metadata":{}},{"cell_type":"code","source":"model_mobilenetV2.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nrlrp_mobilenetV2 = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.01,patience=2,verbose=2,mode=\"auto\",min_delta=0.0001,cooldown=0,min_lr=0)\nmobilenetV2.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.792417Z","iopub.status.idle":"2025-12-08T14:27:13.792834Z","shell.execute_reply.started":"2025-12-08T14:27:13.792621Z","shell.execute_reply":"2025-12-08T14:27:13.792643Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SqueezeNet","metadata":{}},{"cell_type":"code","source":"model_squeezeNet.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\nrlrp_squeezeNet = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.01,patience=2,verbose=2,mode=\"auto\",min_delta=0.0001,cooldown=0,min_lr=0)\nmodel_squeezeNet.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.793907Z","iopub.status.idle":"2025-12-08T14:27:13.794289Z","shell.execute_reply.started":"2025-12-08T14:27:13.794075Z","shell.execute_reply":"2025-12-08T14:27:13.794097Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Custom Model\n\n","metadata":{}},{"cell_type":"code","source":"custom_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\ncustom_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.795366Z","iopub.status.idle":"2025-12-08T14:27:13.795772Z","shell.execute_reply.started":"2025-12-08T14:27:13.795550Z","shell.execute_reply":"2025-12-08T14:27:13.795580Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train and Test Split","metadata":{}},{"cell_type":"code","source":"X, y = train_df[['path', 'classname']], train_df['classname']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.797259Z","iopub.status.idle":"2025-12-08T14:27:13.797664Z","shell.execute_reply.started":"2025-12-08T14:27:13.797422Z","shell.execute_reply":"2025-12-08T14:27:13.797442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.798792Z","iopub.status.idle":"2025-12-08T14:27:13.799174Z","shell.execute_reply.started":"2025-12-08T14:27:13.798963Z","shell.execute_reply":"2025-12-08T14:27:13.798983Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Generators","metadata":{}},{"cell_type":"markdown","source":"### Mobilenet_v2","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.mobilenet_v2 import preprocess_input","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.800076Z","iopub.status.idle":"2025-12-08T14:27:13.800451Z","shell.execute_reply.started":"2025-12-08T14:27:13.800244Z","shell.execute_reply":"2025-12-08T14:27:13.800265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mobilenet_v2_datagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest',\n    preprocessing_function=preprocess_input,\n) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.801449Z","iopub.status.idle":"2025-12-08T14:27:13.801845Z","shell.execute_reply.started":"2025-12-08T14:27:13.801646Z","shell.execute_reply":"2025-12-08T14:27:13.801667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator_mobilenet_v2 = mobilenet_v2_datagen.flow_from_directory(\n        '../input/cattle-disease/train',\n        target_size=(224, 224),  # All images will be resized to 224x224\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.803046Z","iopub.status.idle":"2025-12-08T14:27:13.803466Z","shell.execute_reply.started":"2025-12-08T14:27:13.803245Z","shell.execute_reply":"2025-12-08T14:27:13.803265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_generator_mobilenet_v2 = mobilenet_v2_datagen.flow_from_directory(\n        '../input/cattle-disease/test',\n        target_size=(224, 224),  # All images will be resized to 224x224\n        batch_size=32,\n        class_mode=\"categorical\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.804419Z","iopub.status.idle":"2025-12-08T14:27:13.804840Z","shell.execute_reply.started":"2025-12-08T14:27:13.804615Z","shell.execute_reply":"2025-12-08T14:27:13.804639Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SqueezeNet ","metadata":{}},{"cell_type":"code","source":"train_generator_SqueezeNet = datagen.flow_from_directory(\n        '../input/cattle-disease/train',\n        target_size=(224,224),  # All images will be resized to 160x160\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.806413Z","iopub.status.idle":"2025-12-08T14:27:13.806699Z","shell.execute_reply.started":"2025-12-08T14:27:13.806564Z","shell.execute_reply":"2025-12-08T14:27:13.806579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_generator_SqueezeNet = datagen.flow_from_directory(\n        '../input/cattle-disease/test',\n        target_size=(224,224),  # All images will be resized to 160x160\n        batch_size=32,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.807554Z","iopub.status.idle":"2025-12-08T14:27:13.807871Z","shell.execute_reply.started":"2025-12-08T14:27:13.807708Z","shell.execute_reply":"2025-12-08T14:27:13.807729Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"train_generator_custom_model =datagen.flow_from_directory(\n        '../input/cattle-disease/train',\n        target_size=(64,64),  # All images will be resized to 64x64\n        batch_size=40,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.809687Z","iopub.status.idle":"2025-12-08T14:27:13.809922Z","shell.execute_reply.started":"2025-12-08T14:27:13.809798Z","shell.execute_reply":"2025-12-08T14:27:13.809816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_generator_custom_model = datagen.flow_from_directory(\n        '../input/cattle-disease/test',\n        target_size=(64,64),  # All images will be resized to 64x64\n        batch_size=40,\n        class_mode=\"categorical\",\n        shuffle=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.810571Z","iopub.status.idle":"2025-12-08T14:27:13.810827Z","shell.execute_reply.started":"2025-12-08T14:27:13.810683Z","shell.execute_reply":"2025-12-08T14:27:13.810703Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Fitting","metadata":{}},{"cell_type":"markdown","source":"### Mobilenet_v2","metadata":{}},{"cell_type":"code","source":"history_mobilenet_v2 = model_mobilenetV2.fit(\n      train_generator_mobilenet_v2,\n     validation_data=val_generator_mobilenet_v2,\n      epochs=20,\n      callbacks = [rlrp_mobilenetV2],\n      verbose=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.811850Z","iopub.status.idle":"2025-12-08T14:27:13.812115Z","shell.execute_reply.started":"2025-12-08T14:27:13.811969Z","shell.execute_reply":"2025-12-08T14:27:13.811991Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SqueezeNet","metadata":{}},{"cell_type":"code","source":"history_squeezeNet = model_squeezeNet.fit(\n      train_generator_SqueezeNet,\n     validation_data=val_generator_SqueezeNet,\n      epochs=10,\n       callbacks = [rlrp_squeezeNet], \n      verbose=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.813224Z","iopub.status.idle":"2025-12-08T14:27:13.813516Z","shell.execute_reply.started":"2025-12-08T14:27:13.813343Z","shell.execute_reply":"2025-12-08T14:27:13.813367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"history_custom_model = custom_model.fit(\n      train_generator_custom_model,\n     validation_data=val_generator_custom_model,\n      steps_per_epoch=100,\n      epochs=70,\n      verbose=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.815075Z","iopub.status.idle":"2025-12-08T14:27:13.815367Z","shell.execute_reply.started":"2025-12-08T14:27:13.815196Z","shell.execute_reply":"2025-12-08T14:27:13.815220Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot Loss","metadata":{}},{"cell_type":"markdown","source":"### Mobilenet_v2","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_mobilenet_v2.history['loss'])\nplt.plot(history_mobilenet_v2.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.816574Z","iopub.status.idle":"2025-12-08T14:27:13.816826Z","shell.execute_reply.started":"2025-12-08T14:27:13.816692Z","shell.execute_reply":"2025-12-08T14:27:13.816705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SqueezeNet","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_squeezeNet.history['loss'])\nplt.plot(history_squeezeNet.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.817775Z","iopub.status.idle":"2025-12-08T14:27:13.818016Z","shell.execute_reply.started":"2025-12-08T14:27:13.817889Z","shell.execute_reply":"2025-12-08T14:27:13.817902Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_custom_model.history['loss'])\nplt.plot(history_custom_model.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.818990Z","iopub.status.idle":"2025-12-08T14:27:13.819244Z","shell.execute_reply.started":"2025-12-08T14:27:13.819108Z","shell.execute_reply":"2025-12-08T14:27:13.819130Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot Accuracy","metadata":{}},{"cell_type":"markdown","source":"### Mobilenet_v2","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_mobilenet_v2.history['accuracy'])\nplt.plot(history_mobilenet_v2.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.820588Z","iopub.status.idle":"2025-12-08T14:27:13.821018Z","shell.execute_reply.started":"2025-12-08T14:27:13.820779Z","shell.execute_reply":"2025-12-08T14:27:13.820801Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### SqueezeNet","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_squeezeNet.history['accuracy'])\nplt.plot(history_squeezeNet.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.823169Z","iopub.status.idle":"2025-12-08T14:27:13.823420Z","shell.execute_reply.started":"2025-12-08T14:27:13.823288Z","shell.execute_reply":"2025-12-08T14:27:13.823301Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Custom Model","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.plot(history_custom_model.history['accuracy'])\nplt.plot(history_custom_model.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.824720Z","iopub.status.idle":"2025-12-08T14:27:13.824981Z","shell.execute_reply.started":"2025-12-08T14:27:13.824840Z","shell.execute_reply":"2025-12-08T14:27:13.824853Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Explaniable AI","metadata":{}},{"cell_type":"markdown","source":"## Methods and utils","metadata":{}},{"cell_type":"code","source":"dict_class = {'FMD':0, 'IBK':1, 'LSD': 2}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.825880Z","iopub.status.idle":"2025-12-08T14:27:13.826164Z","shell.execute_reply.started":"2025-12-08T14:27:13.825997Z","shell.execute_reply":"2025-12-08T14:27:13.826020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def gradcam_visualise(data, model, class_index):\n    explainer = GradCAM()\n    output = explainer.explain(data, model, class_index=class_index)\n    return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.827273Z","iopub.status.idle":"2025-12-08T14:27:13.827689Z","shell.execute_reply.started":"2025-12-08T14:27:13.827407Z","shell.execute_reply":"2025-12-08T14:27:13.827430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_data_four(class_name, outputs):\n    fig = plt.figure(figsize=(16, 16))\n    plt.suptitle(classes[class_name])\n    plt.subplot(2,2,1)\n    plt.imshow(outputs[0])\n    plt.subplot(2,2,2)\n    plt.imshow(outputs[1])\n    plt.subplot(2,2,3)\n    plt.imshow(outputs[2])\n    plt.subplot(2,2,4)\n    plt.imshow(outputs[3])\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.828879Z","iopub.status.idle":"2025-12-08T14:27:13.829103Z","shell.execute_reply.started":"2025-12-08T14:27:13.828987Z","shell.execute_reply":"2025-12-08T14:27:13.828999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def grad_cam(model, df_exp, class_name, class_index, image_size):\n    output_data = []\n    classes_df = df_exp[df_exp['classname'] ==  class_name].reset_index(drop = True)\n    for idx,i in enumerate(np.random.choice(classes_df['path'],4)):\n        image = cv2.imread(i)\n        image = cv2.resize(image, image_size)\n        data = ([image], None)\n        output = gradcam_visualise(data, model, class_index)\n        output_data.append(output)\n    plot_data_four(class_name, output_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.830270Z","iopub.status.idle":"2025-12-08T14:27:13.830887Z","shell.execute_reply.started":"2025-12-08T14:27:13.830719Z","shell.execute_reply":"2025-12-08T14:27:13.830742Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Mobilenet_v2","metadata":{}},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    grad_cam(model_mobilenetV2, train_df, class_name, dict_class[class_name], (224,224))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.833227Z","iopub.status.idle":"2025-12-08T14:27:13.833503Z","shell.execute_reply.started":"2025-12-08T14:27:13.833343Z","shell.execute_reply":"2025-12-08T14:27:13.833365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## SqueezeNet","metadata":{}},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    grad_cam(model_squeezeNet, train_df, class_name, dict_class[class_name], (224,224))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.834796Z","iopub.status.idle":"2025-12-08T14:27:13.835190Z","shell.execute_reply.started":"2025-12-08T14:27:13.834962Z","shell.execute_reply":"2025-12-08T14:27:13.834981Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom Model","metadata":{}},{"cell_type":"code","source":"for class_name in train_df['classname'].unique():\n    grad_cam(custom_model, train_df, class_name, dict_class[class_name], (64,64))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.836161Z","iopub.status.idle":"2025-12-08T14:27:13.836553Z","shell.execute_reply.started":"2025-12-08T14:27:13.836334Z","shell.execute_reply":"2025-12-08T14:27:13.836354Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Save","metadata":{}},{"cell_type":"code","source":"model_mobilenetV2.save('./model_mobilenetV2.h5')\nmodel_squeezeNet.save('./model_squeezeNet.h5')\ncustom_model.save('./custom_model.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T14:27:13.837884Z","iopub.status.idle":"2025-12-08T14:27:13.838262Z","shell.execute_reply.started":"2025-12-08T14:27:13.838053Z","shell.execute_reply":"2025-12-08T14:27:13.838074Z"}},"outputs":[],"execution_count":null}]}